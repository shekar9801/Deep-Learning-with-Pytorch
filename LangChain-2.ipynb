{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5991aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install langchain_google_genai\n",
    "!pip -q install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f9ec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "chat_google = ChatGoogleGenAI(model='gemnini-1.5-pro')\n",
    "result = chat_google.invoke(\"what is the capital of india?\")\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddc1a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa2910b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is **Newâ€¯Delhi**.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "hf_token = os.getenv(\"HUGGINGFACEHUB_ACCESS_TOKEN\")\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"openai/gpt-oss-20b\",\n",
    "    task=\"text-generation\",\n",
    "    huggingfacehub_api_token=hf_token\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "response = model.invoke(\"what is the capital of india.\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d66030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"openai/gpt-oss-20b\",\n",
    "    task=\"text-generation\",\n",
    "    huggingfacehub_api_token=hf_token\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=3, memory_key=\"history\",return_messages=True)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a Order Tracking Assistant.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=model,\n",
    "    prompt=prompt,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"prompt: \")\n",
    "    print(f'Prompt: {user_input}')\n",
    "    if user_input.lower() == 'exit':\n",
    "        print('Response : GoodBye....')\n",
    "        break\n",
    "\n",
    "    response = chain.invoke({\"input\": user_input})\n",
    "    print(f\"Response: {response['text']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a591ee2e",
   "metadata": {},
   "source": [
    "**HuggingFacePipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b7405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"openai/gpt-oss-20b\",\n",
    "    task=\"text-generation\",\n",
    "    pipelin_kwargs=dict(\n",
    "        temperatur=0.5,\n",
    "        max_new_tokens=100\n",
    "    )\n",
    "\n",
    ")\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "result = model.invoke(\"what is the capital of india.\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b3dfcd",
   "metadata": {},
   "source": [
    "3. Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf526e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"openai/gpt-oss-20b\",\n",
    "    task=\"text-generation\",\n",
    "    pipelin_kwargs=dict(\n",
    "        temperatur=0.5,\n",
    "        max_new_tokens=100\n",
    "    )\n",
    "\n",
    ")\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "result = model.invoke(\"what is the capital of india.\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a30ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6b3061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-large', dimensions=32)\n",
    "\n",
    "documents = [\n",
    "    \"Delhi is the capital of India\",\n",
    "    \"Mumbai is the capital of Maharastra\",\n",
    "    \"Kolkata is the capital of West Bengal\",\n",
    "    \"Hyderabad is the capital of Telangana\"\n",
    "]\n",
    "result = embedding.embed_query(\"Delhi is the capital of India\")\n",
    "print(str(result))\n",
    "\n",
    "\n",
    "result = embedding.embed_documents(documents)\n",
    "print(str(result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9305e0f",
   "metadata": {},
   "source": [
    "**all-MiniLM-L6-v2**\n",
    "1. This is a sentence-transformers model:\n",
    "* It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search.\n",
    "\n",
    "2. Usage (Sentence-Transformers)\n",
    "* Using this model becomes easy when you have sentence-transformers installed:\n",
    "\n",
    "```\n",
    "pip install -U sentence-transformers\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15219e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "embedding = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2', )\n",
    "text = 'This is a test document.'\n",
    "result = embedding.embed_query(text)\n",
    "print(str(result))\n",
    "\n",
    "\n",
    "documents = [\n",
    "    \"Delhi is the capital of India\",\n",
    "    \"Mumbai is the capital of Maharastra\",\n",
    "    \"Kolkata is the capital of West Bengal\",\n",
    "    \"Hyderabad is the capital of Telangana\"\n",
    "]\n",
    "\n",
    "result = embedding.embed_documents(documents)\n",
    "print(str(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d19381",
   "metadata": {},
   "source": [
    "**Semantic Search Using the cosine similary and Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c3dbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9c663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-large', dimensions=300)\n",
    "\n",
    "documents = [\n",
    "    \"Virat Kohli is an Indian cricketer known for his aggressive batting and leadership.\",\n",
    "    \"MS Dhoni is a former Indian captain famous for his calm demeanor and finishing skills.\",\n",
    "    \"Sachin Tendulkar, also known as the 'God of Cricket', holds many batting records.\",\n",
    "    \"Rohit Sharma is known for his elegant batting and record-breaking double centuries.\",\n",
    "    \"Jasprit Bumrah is an Indian fast bowler known for his unorthodox action and yorkers.\"\n",
    "]\n",
    "\n",
    "query = 'tell me about bumrah'\n",
    "\n",
    "doc_embeddings = embedding.embed_documents(documents)\n",
    "query_embedding = embedding.embed_query(query)\n",
    "\n",
    "scores = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "\n",
    "index, score = sorted(list(enumerate(scores)),key=lambda x:x[1])[-1]\n",
    "\n",
    "print(query)\n",
    "print(documents[index])\n",
    "print(\"similarity score is:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371ca95f",
   "metadata": {},
   "source": [
    "<h2>Prompts</h2>\n",
    "\n",
    "1.   Text based prompt\n",
    "2.   Multimodel prompt - text, audio, video, images\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc13f30",
   "metadata": {},
   "source": [
    "1.  The below code uses the native memory for maintaining the conversational history.\n",
    "2.  For the role in the memory i have used the SystemMessage, HumanMessage, AIMessage which differentiates the roles in history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3774a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "\n",
    "model = HuggingFaceEndpoint(repo_id='openai/gpt-oss-20b', task='text-generation', huggingfacehub_api_token=hf_token)\n",
    "model = ChatHuggingFace(llm=model)\n",
    "\n",
    "history = [SystemMessage(content='You are a helpful assistant')]\n",
    "\n",
    "while True:\n",
    "  prompt = input(\"Prompt: \")\n",
    "  if prompt.lower() == 'exit':\n",
    "    break\n",
    "  history.append(HumanMessage(content=prompt))\n",
    "  response = model.invoke(history)\n",
    "  print(f'AI: {response.content:}')\n",
    "  history.append(AIMessage(content=response.content))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b279617",
   "metadata": {},
   "source": [
    "* The below code download the model locally from Huggingface and uses it for text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f57cacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install -U langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2f25b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip -q install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "934aeb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|im_start|>user\n",
      "What is the capital of India?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "The capital of India is New Delhi. It has been serving as the capital since 1876, although the territory now known as New Delhi was not officially established as the capital until 1911 when the British government moved the capital from Calcutta (now Kolkata) to Delhi. New Delhi is the political, administrative, and cultural hub of India, housing numerous important government buildings, embassies, and historical monuments.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
    "\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"LiquidAI/LFM2-1.2B\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs=dict(\n",
    "        temperature=0.5,\n",
    "        max_new_tokens=100\n",
    "    )\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "result = model.invoke(\"What is the capital of India?\")\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03d8bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
